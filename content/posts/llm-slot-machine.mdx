---
title: The LLM Slot Machine
summary: Near-misses keep you pulling the lever. Slot machines figured this out decades ago. Now your AI coding assistant is doing the same thing.
date: 2025-12-16
image: /slot-machine.jpg
imageAlt: Scene from Fear and Loathing in Las Vegas at slot machines
tags: [AI, developer-tools, psychology]
---

Do you ever find yourself jonesing to ask Claude to do something you're not sure it can do? And then obsessively trying to get it to do the thing *just* the way you want?

Maybe that's just me. But I deeply suspect it's not.

I'll ask it to implement a feature. It gets close. Really close. Not quite what I wanted, but damn near. So I send another message and try again. It gets closer. Still not perfect. One more try.

Twenty minutes later I realize I could have just taken the first attempt and fixed it myself in five.

It reminded me of something I learned about slot machines.

## The Near-Miss Effect

In the gambling world, there's this concept called the "near-miss." Two cherries line up, and the third one lands *just* above or below the payline. You didn't win. But you were *so close*.

Here's the thing. Slot machines used to be mechanical. Fully random. The house had a slight edge, but every spin was truly independent.

<img src="/slot-machine.jpg" alt="Slot machine reels" className="w-full max-w-none" />

Then they went digital.

Regulators said: "Fine, but you have to keep the same payout percentage." So a machine with a 92% return-to-player rate on a mechanical machine had to maintain that rate digitally. Fair enough.

But here's what they *didn't* regulate: **how often you could show someone a near-miss.**

With a mechanical machine, near-misses happened randomly based on the physical reels. With a digital one, you could engineer them. Show that third cherry one position off the payline. Make it *look* like the player almost won, even though the RNG had already determined it was a loss.

The gambling industry figured out something dark: **near-misses were more effective at keeping people gambling than actual wins.**

## Your Brain on Near-Misses

[Researchers at Cambridge](https://www.jneurosci.org/content/30/18/6180) ran fMRI studies on gamblers and found that near-misses activate the same reward centers as actual wins. Your brain releases dopamine despite getting no reward.

Even stranger: if you have a gambling addiction, the near-miss response is *stronger*. Your brain literally treats near-misses as incomplete wins, not as losses.

## The LLM Slot Machine

Back to Claude.

I ask it to refactor a component. It does it. The logic is mostly right. The structure is close. But it misses an edge case. Or it doesn't match my naming conventions. Or it breaks something subtle in how the state updates.

It's a near-miss.

My brain treats this differently than if it had produced garbage. If it gave me nonsense, I'd just do it myself. But because it got *close*, I think: "One more message and it'll get it."

So I clarify. I add more context. I point out what it missed. It tries again. Gets closer. Still not _quite_ right.

I keep pulling the lever.

**The problem isn't that the LLM is bad.** It's optimized to give you something plausible, something that passes a quick scan but fails on execution. Something 80% of the way there.

That 80% is the third cherry landing one row off.

## The Accidental Dark Pattern

Here's what I find interesting. Facebook, Instagram, and Twitter all spent years trying to reverse-engineer gambling psychology. Variable rewards. Notifications timed to pull you back. They studied this stuff and built it in deliberately.

LLMs just... have it. By accident. The near-miss isn't a feature they designed. It's just what the product *is* right now. And as they get better, and we expect more from them, the near-misses continue. It was *so close* to perfect.

As a heavy user of LLMs, this realization worries me...but I think I can keep myself from getting addicted...

I hope so ðŸ¤ž
